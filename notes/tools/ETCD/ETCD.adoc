= ETCD =
Korov9 <korov9@163.com>
v1.0 2021-10-31
:toc: right
:imagesdir: images
:homepage: http://asciidoctor.org
:source-highlighter: pygments
:source-language: java

== Raft协议

=== Leader选举

在Raft协议中，每个节点都维护了一个状态机，该状态机有三种状态：Leader、Foller和Candidate。在任意时刻，集群中的任意一个节点都处于这三个状态之一。各个状态和转换条件如图所示

image::Snipaste_2021-11-10_00-00-11.png[]

在多数情况下，集群中有一个Leader节点，其他节点都处于Follower状态，

. Leader节点负责处理所有客户端的请求，当接受到客户端的写入请求时，Leader节点会在本地追加一条相应的日志，然后将其封装成消息发送到集群中其他的Follower节点。当Follower节点收到该消息时会对其进行响应。如果集群中多数（超过半数）节点都已经收到该请求对应的日志记录时，则Leader节点认为该条日志记录已提交（committed），可以向客户端返回响应。Leader还会处理客户端的只读请求。Leader节点另一项工作时定期向集群中的Follower节点发送心跳消息，这主要是为了防止集群中的其他Follower节点的选举计时器超时而触发新一轮选举
. Follower节点不会发送任何请求，他们只是简单的相应来自Leader或者Candidate的请求；Follower节点也不会处理Client的请求，而是将请求重定向给集群中的Leader节点
. Candidte节点是由Follower节点转换而来的，当Follower节点长时间没有收到Leader节点发送的心跳消息时，则该节点的选举计时器就会过期，同时将自身状态转换成Candidate，发起新一轮选举。

在Raft协议中有两个时间控制Leader选举发生，其中一个是选举超时时间（election timeout），每个Follower节点在接收不到Leader节点的心跳消息之后，并不会立即发起新一轮选举，而是需要等待一段时间之后才切换成Candidate状态发起新一轮选举。这段等待时长就是这里所说的election timeout。之所以这样设计，主要是Leader节点发送的心跳消息可能因为瞬间的网络延迟或程序瞬间的卡顿而迟到（或是丢失），因此就触发新一轮选举是没有必要的。election timeout一般设置为150ms~300ms之间的一个随机数。另一个超时时间是心跳的超时时间（heartbeat timeout），也就是Leader节点向集群中其他Follower节点发送心跳消息的时间间隔。

当集群初始化时，所有节点都处于Follower的状态，此时的集群中没有Leader节点。当Follower节点一段时间（选举计时器超时）内收不到Leader节点的心跳消息，则认为Leader节点出现故障导致任期（Term）过期，Follower节点会转换成Candidate状态，发起新一轮的选举。任期实际上是一个全局的、连续递增的整数，在Raft协议中每进行一次选举，任期加一，在每个节点中都会记录当前的任期值（currentTerm）。每一个任期都是从一次选举开始的，在选举时，会出现一个或多个Candidte节点尝试成为Leader节点，如果其中一个Candidate节点赢得选举，则该节点就会切换为Leader状态并成为该任期的Leader节点，直到该任期结束。

假设有三个节点A、B、C。A由于长时间未收到Leader的心跳消息，就会切换成为Candidate并发起选举（A的选举计时器election timer已被重置）。在选举的过程中，节点A首先将自己的选票投给自己，并会向集群中其他节点发送选举请求（Request Vote）以获取选票，如图1所示；此时节点B和C还都是处于Term=0的任期中，且都是Follower状态，均未透出Term=1任期中的选票，所以节点B和C在接受到A的选举请求后会选票投给节点A，另外节点B和C在收到节点A的选举请求的同时会将选举定时器重置，这是为了防止一个任期中同时出现多个Candidate节点，导致选举失败，如图2所示

image::Snipaste_2021-11-10_00-48-59.png[]

在节点A收到节点B、C的投票之后，其收到了集群中超过半数的选票，所以在Term=1这个任期中，该集群的Leader节点就是节点A，其他节点将切换成Follower状态。集群中的节点除了记录当前任期号（currentTerm），还会记录在该任期中当前节点的投票结果（VoteFor）

image::Snipaste_2021-11-10_00-55-10.png[]

A成为Term=1任期的Leader节点之后，节点A会定期向集群中的其他节点发送心跳消息，这样就可以防止节点B和C中的需那句计时器（election timer）超时而触发新一轮的选举；当节点B和C收到节点A的心跳消息之后会重置选举计时器。由此可见心跳超时时间（heartbeat timeout）需要远小于选举超时时间（election timeout）

image::Snipaste_2021-11-10_00-58-30.png[]

如果有两个或两个以上节点的选举计时器同时过期，则这些节点会同时由Follower状态切换成Candidate状态，然后同时触发新一轮选举，在该轮选举中，每个Candidate节点获取的选票都不到半数，怎么办？假设集群中有4个节点，其中A节点和B节点的选举计时器同时到期，切换到Candidte状态并向集群中其他节点发送选举请求，假设A节点发出的选举请求先抵达C，B的选举请求先抵达D，则A和B都获得了两票。在这种情况下Term=4这个任期会以选举失败结束，随着时间的流逝，当任意节点的选举计时器到期之后，会再次发起新一轮的选举。前面提到election timeout是在一个时间区间内取的随机数，所以在配置合理的时候，像上述情况出现的概率并不大。

image::Snipaste_2021-11-10_01-06-31.png[]

这里假设节点A的选举计时器再次到期（此次节点B，C，D的选举计时器并未到期），它会切换成Candidate状态并发起新一轮选举（Term=5），其中节点B虽然处于Candidate状态，但是接收到Term值比自身记录Term值大的请求时，节点会切换成Follower状态并更新自身记录的Term值，所以该实例中的节点B也会将选票投给A

image::Snipaste_2021-11-10_01-10-33.png[]

在获取集群中半数以上的选票并成为新任期（Term=5）的Leader之后，节点A会定期向集群中其他节点发送心跳消息；当集群中其他节点收到Leader节点的心跳消息的时候，会重置选举定时器

当集群中的Leader宕机之后，一段时间之后其他节点会触发Leader选举，选举成功之后Term=6，此时宕机的节点恢复之后会收到Term=6的心跳，恢复的节点的Term=5，此时恢复的节点会切换为Follower，并更新自己的任期号。

Leader选举是Raft算法中对时间要求较为严格的一个点，一般要求整个集群中的时间满足如下不等式： `广播时间 << 选举超时时间 << 平均故障时间`。

广播时间指的是从一个节点发送心跳消息到集群中其他节点并接收响应的平均时间；平均故障时间就是对于一个节点而言，两次故障之间的平均时间。广播时间必须比选举时间小一个数量级，这样Leader节点才能够发送稳定的心跳消息来重置其他Follower节点的选举计时器，从而防止他们切换成Candidate，触发新一轮选举。

=== 日志复制

Leader节点除了向Follower节点发送心跳消息，还会处理客户端的请求，并将客户端的更新操作以消息（Append Entries消息）的形式发送到集群中所有的Follower节点。当Follower节点记录收到的这些消息之后，会向Leader节点返回相应的响应消息。当Leader节点在收到半数以上的Follower节点的响应消息之后，会对客户端的请求进行应答。最后，Leader会提交客户端的更新操作，该过程会发送Append Entries消息到Follower节点，通知Follower节点该操作已经提交，同时Leader节点和Follower节点也就可以将该操作应用到自己的状态机中。

假设当前集群中有三个节点（A、B、C）。其中A是Leader节点，此时有一个客户端发送了一个更新操作到集群。节点A会将该更新操作记录到本地的Log中如图所示

image::Snipaste_2021-11-10_12-26-26.png[]

之后节点A会向其他节点发送Append Entries消息，其中记录了Leader节点最近接受到的请求日志，集群中其他Follower节点收到该Append Entries消息之后，会将该操作记录到本地Log中，并返回响应的响应消息，如图所示

image::Snipaste_2021-11-10_12-28-07.png[]

当Leader节点收到半数以上的响应消息之后，会认为集群中有半数以上的节点已经记录了该更新操作，Leader节点会将该更新操作对应的日志记录设置未已提交（committed），并应用到自身的状态机中。同时Leader节点还会对客户端的请求作出响应。同时Leader节点还会向集群中其他Follower节点发送消息，通知他们该更新操作已经被提交，Follower节点收到该消息之后，才会将该更新操作应用到自己的状态机中，如图所示

image::Snipaste_2021-11-10_12-31-19.png[]

集群中各个节点都会维护一个本地Log用于记录更新操作，除此之外，每个节点还会维护commitIndex和lastApplied两个值，他们是本地Log的索引值，其中commitIndex表示的是当前节点已知的、最大的、已提交的日志索引值，lastApplied表示的是当前节点最后一条被应用到状态机中的日志索引值。当节点中的commitIndex值大于lastApplied值时，会将lastApplied加1，并将lastApplied对应的日志应用到状态机中。

Leader节点中不仅需要知道自己的上述信息，还需要了解集群中其他Follower节点的这些信息，例如，Leader节点需要了解每个Follower节点的日志复制到哪个位置，从而决定下次发送Append Entries消息中包含那些日志记录。为此，Leader节点会维护nexIndex[]和matchIndex[]两个数组，这两个数组中记录的都是日志索引值，其中nextIndex[]数组记录了需要发送给每个Follower节点的下一条日志的索引值，matchIndex[]表示记录了已经复制给每个Follower节点的最大的日志索引值。

假设集群中有三个节点，A是Leader（Term=1），而Follower节点C因为宕机导致有一段时间未与Leader节点同步日志。此时节点C的Log中并不包含全部的已提交日志，而只是节点A的Log的子集，节点C排除故障重新启动，当前集群的状态如图所示

image::Snipaste_2021-11-10_12-44-33.png[]

A作为Leader节点，记录了nextIndex[]和matchIndex[]，所以知道应该向节点C发送哪些日志，在本例中，Leader节点在下次发送Append Entries消息时会携带index=2的消息（这里为了描述简单，每条消息只携带单条日志，Raft协议采用批量发送的方式，这样效率更高），当节点C收到Append Entries消息后，会将日志记录到本地Log中，然后向Leader节点返回追加日志成功的响应，当Leader节点收到响应之后，会递增节点C对应的nextIndex和matchIndex，这样Leader节点就知道下次发送日志的位置了。

image::Snipaste_2021-11-10_12-48-38.png[]

当C故障恢复后，节点A宕机重启，并且导致节点B成为新任（Term=2）的Leader节点，则此时节点B并不知道旧Leader节点中记录的nextIndex[]和matchIndex[]信息，所以Leader节点会重置nextIndex[]和matchIndex[]，其中会将nextIndex[]全部重置为其自身Log的最后一条已提交日志的Index值，而matchIndex[]全部重置为0，

image::Snipaste_2021-11-10_12-52-02.png[]

随后，新任期中的Leader节点会向其他节点发送Append Entries消息，节点A已经拥有了当前Leader的全部日志记录，所以会返回追加成功的响应并等待后续的日志，而节点C并没有Index=2和Index=3两条日志，所以返回追加日志失败的响应，在收到该响应后，Leader节点会向nextIndex前移，然后Leader节点会再次尝试发送Append Entries消息，循环往复，不断减小nextIndex值，直至节点C返回追加成功的响应，之后就进入了正常追加消息记录的流程。

image::Snipaste_2021-11-10_12-56-15.png[]

Follower节点投票的时候还需要比肩Candidate节点的日志记录与自身的日志记录，拒绝那些没有自己新的Candidate节点发来的投票请求，确保将选票投给包含了全部已提交（committed）日志记录的Candidate节点，这也保证了已提交的日志记录不会丢失：Candidate节点为了成为Leader节点必然会在选举过程中向集群中半数以上的节点发送选举请求，因为已提交的日志记录必须存在集群中半数以上的节点中，这也就意味着每一条已提交的日志记录肯定在这些接收到节点中至少存在一份。如果Candidate节点上的日志记录与集群中大多数节点上的日志记录一样新，那么其日志一定包含所有已经提交的日志记录，也就可以获得这些节点的投票并成为Leader。

Raft协议通过比较两节点日志中的最后一条日志的索引值和任期号，以决定谁的日志比较新：首先会比较最后一条日志记录的任期号，如果最后的日志记录的任期号不同，那么任期号大的日志记录比较新；如果最后一条日志记录的任期号相同，那么日志索引比较大的比较新。

=== 网络的分区场景

在一个集群中如果有部分节点的网络发生故障，与集群中一部分节点的链接中断，就会出现网络分区，如图集群有A、B、C、D、E五个节点，其中节点A、B相互之间网络联通，节点C、D、E相互之间网络联通，但是这两个部分节点之间出现网络故障，这就形成了网络分区

image::Snipaste_2021-11-10_23-59-03.png[]

假设此时A是Leader，他会向集群中其他四个节点发送Append Entries消息和心跳消息，当出现网络分区时，节点A的心跳只有节点B才能收到，而集群中其他的节点收不到。随着时间的流逝，集群中与Leader节点隔离的网络分区（C、D、E    ）中，会率先有一个节点的选举计时器（election timer）超时，这里假设该节点是E，此时的节点E就会切换成Candidate状态并发起下一轮选举，由于网络分区，当前集群中只有节点C、D能够收到节点E的选举请求，这里假设C、D都会将选票投给节点E

image::Snipaste_2021-11-11_00-05-27.png[]

到此为止，节点E在此次选举中得到了三票，达到集群半数以上，所以节点E成为新任期（Term=2）的Leader节点。当网络故障被修复时，上述的网络分区就会消失，此时节点A（Term=1的Leader节点）发送的心跳消息会被节点C、D、E接收到，但是这些心跳消息中携带的Term值小于当前C、D、E节点的Term值，会被C、D、E节点忽略；同时节点E（Term=2任期的Leader）发送的心跳消息会被节点A、B接收到，因为Term更大，所以A、B节点会切换成Follower状态，这样整个集群中的Leader节点依旧是E。

读者可能会问：如果网络分区时，Leader节点划分到节点较多的分区中，此时节点较少的分区中，会有节点的选举计时器超时，且换成Candidate状态并发起新一轮的选举，但是由于该分区中节点数不足半数，所以无法选举出新的Leader节点，等待一段时间之后，该分区中又会出现某个节点的选举计时器超时，会再次发起新一轮的选举，循环往复，从而导致不断发起选举，Term号不断增长。

在Raft协议中对这种情况有一个优化，当某个节点要发起选举之前，需要先进入一个叫作PreVote的状态，在该状态下，节点会先尝试连接集群中的其他节点，如果能够成功连接到半数以上的节点，才能真正发起新一轮的选举。通过这种方式可以解决上述的问题。

另一个需要介绍的问题是，网络分区场景下，客户端与集群的交互过程及日志复制的过程。这里我们先简单介绍一下客户端如何与集群进行交互并找到集群的Leader节点。集群中只有Leader节点可以处理客户端发来的请求，当Follower节点收到客户端的请求时，也必须将Leader节点信息告知客户端，然后由Leader节点处理请求，具体过程如下

- 当客户端初次连接到集群时，会随即挑选一个服务器节点进行通信
- 如果客户端第一次挑选的节点不是Leader节点，那么该节点会拒绝客户端的请求，并且将他所知道的Leader信息返回给客户端。
- 当客户端连接到Leader节点之后，即可发送消息进行交互
- 如果在交互过程中Leader节点宕机，那么客户端的请求会超时，客户端会再次随机挑选集群中的节点，并从步骤1重新开始执行

这里依然通过一个实例来介绍整个过程，假设集群依然有五个节点，在未发生网络分区时，节点A为集群的Leader节点，此时客户端请求会发送到节点A，经过前面描述的日志复制过程后，节点A也会向客户端返回响应。当节点A、B与节点C、D、E之间发生网络分区之后，客户端发往节点A的请求将会超时，这主要时以为内A无法将请求发送到集群中超过半数的节点上，该请求响应的日志记录也就无法提交，从而导致无法给客户端返回相应的响应，此时另外一个分区中的E节点被选举为Leader，当请求超时之后，客户端会重新随机选择一个节点并获取Leader节点信息，客户端最终会连接到节点E并发送请求，而该网络分区中有超过半数节点，请求对应的日志记录可以提交，所以客户端的请求不会再次出现超时，之后客户端会一直与节点E进行交互。

=== 日志的压缩与快照

随着客户端与集群不断的交互，每个节点上的日志记录会不断增加，但是服务器的空间都是有限的，日志量布不能无限制的增长，另外，在节点重启时会重放日志记录，如果日志量记录过多，则需要花费较长的时间完成重放操作。这就需要压缩和清洗机制来减少日志量。

定期生成快照时最常见的也是最简单的压缩方法。在创建快照文件时，会将整个节点的状态进行序列化，然后写入稳定的持久化存储中，这样，在该快照文件之前的日志记录就可以全部丢弃了。

在快照中除了节点当前的数据状态，还包含了其最后一条日志记录的任期号和索引号，如图所示，该快照包含了6条日志记录，在快照的元数据中记录了第6条日志记录的任期号和索引号，在生成快照文件之后，即可将1～6条日志记录丢弃了

image::Snipaste_2021-11-11_03-23-52.png[]

一般情况下，集群中每个节点都会自己独立、定时的创建快照，在其状态恢复时，都会使用自己本地最新的快照数据。如果Follower节点长时间宕机（或是刚刚加入集群的新节点），就有可能导致其日志记录远远落后于当前的Leader节点，与此同时，Leader节点中陈旧的日志记录都已被删除。在这种场景下，为了将该Follower节点恢复到正确的状态，Leader节点会将快照发送给该Follower节点，Follower节点会使用该快照数据进行恢复。发送快照时使用特殊的消息类型（快照消息）。etcd的网络层为了高效的传输消息，会将快照的发送与普通消息（Append Entries消息、心跳消息）的发送分开在不同的消息通道中完成

当Follower节点接收到该快照消息时，必须决定如果处理已存在的日志记录。一般情况下，快照已包含了该Follower节点中不存在的日志记录，此时Follower节点直接丢弃所有的日志记录，因为这些日志最终会被Leader传递来的快照所替代。如果Follower节点接收到的快照只包含了自己本地日志的一部分，那么该快照所包含的全部日志记录会被全部删除，但是快照之后的日志则会保留。

=== 其他技术

==== linearizable语义

Raft协议的目标是实现linearizable语义，即在客户端每次向集群发送一次请求时，该请求只会被执行一次。但是根据前面的描述，客户端虽然只是想发送一次请求，但是集群中可能多次收到该请求。例如Leader节点负责提交日志记录并将日志记录应用到其状态机中，但是在向客户端返回响应的响应消息之前宕机了，那么客户端会连接到新的Leader节点并重放对应的请求，这就导致该请求再次被执行。或者，网络出现故障，导致请求丢失或是延迟，就会导致一个请求被执行两次

常见的解决方案就是客户端对于每个请求都产生一个唯一的序列号，然后由服务端为每个客户端维护一个Session，并对每个请求进行去重。

== ETCD 特性 ==

- Lease机制：即租约机制（TTL，Time To Live），Etcd 可以为存储的 KV 对设置租约，当租约到期，KV 将失效删除；同时也支持续约，即 KeepAlive。
- Revision 机制：每个 key 带有一个 Revision 属性值，etcd 每进行一次事务对应的全局 Revision 值都会加一，因此每个 key 对应的 Revision 属性值都是全局唯一的。通过比较 Revision 的大小就可以知道进行写操作的顺序。
- 在实现分布式锁时，多个程序同时抢锁，根据 Revision 值大小依次获得锁，可以避免 “羊群效应” （也称 “惊群效应”），实现公平锁。
- Prefix 机制：即前缀机制，也称目录机制。可以根据前缀（目录）获取该目录下所有的 key 及对应的属性（包括 key, value 以及 revision 等）。
- Watch 机制：即监听机制，Watch 机制支持 Watch 某个固定的 key，也支持 Watch 一个目录（前缀机制），当被 Watch 的 key 或目录发生变化，客户端将收到通知。

